{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2157fae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sin2x\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "from datasets import load_dataset, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5d6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных из JSON файла\n",
    "def load_poems(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236d5b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных для обучения\n",
    "def prepare_dataset(poems):\n",
    "    texts = []\n",
    "    for poem in poems.values():\n",
    "        texts.append(\"\\n\".join(poem))  # Объединяем строки стихотворения в один текст\n",
    "    return Dataset.from_dict({\"text\": texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea56e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация стихотворения\n",
    "def generate_poem(model, tokenizer, prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=100)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee055052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "\n",
    "def calculate_chrf(reference_texts, generated_texts):\n",
    "    # reference_texts - список строк с эталонными текстами\n",
    "    # generated_texts - список строк с сгенерированными текстами\n",
    "    chrf_score = sacrebleu.corpus_chrf(generated_texts, [reference_texts], char_order=6)\n",
    "    return chrf_score.score\n",
    "\n",
    "def calculate_perplexity(model, tokenizer, texts):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "            outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            total_loss += outputs.loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(texts)\n",
    "    perplexity = torch.exp(torch.tensor(avg_loss))\n",
    "    return perplexity.item()\n",
    "\n",
    "def calculate_novelty(reference_texts, generated_texts):\n",
    "    reference_set = set(reference_texts)\n",
    "    unique_generated = set(generated_texts)\n",
    "    \n",
    "    novelty_score = len(unique_generated - reference_set) / len(unique_generated) if unique_generated else 0\n",
    "    return novelty_score\n",
    "\n",
    "def calculate_distinct_n(generated_texts, n=2):\n",
    "    ngrams = set()\n",
    "    for text in generated_texts:\n",
    "        tokens = text.split()  # Разделение на слова\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            ngram = tuple(tokens[i:i+n])\n",
    "            ngrams.add(ngram)\n",
    "    \n",
    "    distinct_n_score = len(ngrams) / sum(len(text.split()) for text in generated_texts)\n",
    "    return distinct_n_score\n",
    "\n",
    "def llm_as_judge(model, tokenizer, texts):\n",
    "    scores = []\n",
    "    \n",
    "    for text in texts:\n",
    "        inputs = tokenizer(f\"Оцените качество следующего стихотворения от 1 до 10:\\n{text}\", return_tensors=\"pt\")\n",
    "        outputs = model.generate(**inputs)\n",
    "        score_str = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Предполагаем, что оценка будет в формате \"Оценка: X\"\n",
    "        score = int(score_str.split(\":\")[-1].strip())\n",
    "        scores.append(score)\n",
    "\n",
    "    average_score = sum(scores) / len(scores) if scores else 0\n",
    "    return average_score\n",
    "\n",
    "\n",
    "def evaluate_model(model, tokenizer, reference_texts, generated_texts):\n",
    "    chrf_score = calculate_chrf(reference_texts, generated_texts)\n",
    "    perplexity_score = calculate_perplexity(model, tokenizer, generated_texts)\n",
    "    distinct_n_score = calculate_distinct_n(generated_texts)\n",
    "    novelty_score = calculate_novelty(reference_texts, generated_texts)\n",
    "    llm_judge_score = llm_as_judge(model, tokenizer, generated_texts)\n",
    "\n",
    "    print(f\"chrF++: {chrf_score:.4f}\")\n",
    "    print(f\"Perplexity: {perplexity_score:.4f}\")\n",
    "    print(f\"Distinct-n: {distinct_n_score:.4f}\")\n",
    "    print(f\"Novelty: {novelty_score:.4f}\")\n",
    "    print(f\"LLM-as-judge score: {llm_judge_score:.4f}\")\n",
    "\n",
    "# Пример вызова функции оценки после обучения модели:\n",
    "# evaluate_model(model, tokenizer, reference_poems_list, generated_poems_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d5f8490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics):\n",
    "    plt.plot(metrics['train_loss'], label='Train Loss')\n",
    "    plt.plot(metrics['eval_loss'], label='Eval Loss')\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.title('Training and Evaluation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b4a7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "poems = load_poems('data/poems.json')\n",
    "    \n",
    "# Подготовка датасета\n",
    "dataset = prepare_dataset(poems)\n",
    "\n",
    "# Загрузка предобученной модели и токенизатора\n",
    "model_name = \"gpt2\"  # Вы можете выбрать другую модель из Hugging Face Model Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15aef347",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "--load_best_model_at_end requires the save and eval strategy to match, but found\n- Evaluation strategy: IntervalStrategy.EPOCH\n- Save strategy: SaveStrategy.STEPS",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Настройка параметров обучения\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./results\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./logs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_for_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mloss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgreater_is_better\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Создание экземпляра Trainer с добавлением EarlyStoppingCallback\u001b[39;00m\n\u001b[32m     17\u001b[39m trainer = Trainer(\n\u001b[32m     18\u001b[39m     model=model,\n\u001b[32m     19\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     callbacks=[EarlyStoppingCallback(early_stopping_patience=\u001b[32m5\u001b[39m)]  \u001b[38;5;66;03m# Установите patience на 5 эпох\u001b[39;00m\n\u001b[32m     23\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:132\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, tp_size, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sin2x\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1648\u001b[39m, in \u001b[36mTrainingArguments.__post_init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1646\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.load_best_model_at_end \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save_strategy != SaveStrategy.BEST:\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.eval_strategy != \u001b[38;5;28mself\u001b[39m.save_strategy:\n\u001b[32m-> \u001b[39m\u001b[32m1648\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1649\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m--load_best_model_at_end requires the save and eval strategy to match, but found\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m- Evaluation \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1650\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstrategy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.eval_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m- Save strategy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.save_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1651\u001b[39m         )\n\u001b[32m   1652\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.eval_strategy == IntervalStrategy.STEPS \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save_steps % \u001b[38;5;28mself\u001b[39m.eval_steps != \u001b[32m0\u001b[39m:\n\u001b[32m   1653\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.eval_steps < \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save_steps < \u001b[32m1\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: --load_best_model_at_end requires the save and eval strategy to match, but found\n- Evaluation strategy: IntervalStrategy.EPOCH\n- Save strategy: SaveStrategy.STEPS"
     ]
    }
   ],
   "source": [
    "# Настройка параметров обучения\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=500,\n",
    "    eval_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"loss\",\n",
    "    greater_is_better=False,\n",
    ")\n",
    "\n",
    "# Создание экземпляра Trainer с добавлением EarlyStoppingCallback\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,  # Для простоты используем тот же датасет для оценки\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]  # Установите patience на 5 эпох\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Обучение модели\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38084db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели после обучения\n",
    "model.save_pretrained('./poem_generator')\n",
    "tokenizer.save_pretrained('./poem_generator')\n",
    "\n",
    "# Оценка качества модели (здесь вы можете добавить свою реализацию)\n",
    "evaluate_model(model, tokenizer, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d208a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"На лугу цветы\"\n",
    "print(generate_poem(model, tokenizer, prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
